#!/usr/bin/env bash
set -euo pipefail

# Resolve root directory of the script
ROOT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
cd "$ROOT_DIR"

# --------------- Directory scaffolding ---------------
mkdir -p "$ROOT_DIR/models/presumm" \
         "$ROOT_DIR/data/reverse_attribution" \
         "$ROOT_DIR/outputs" \
         "$ROOT_DIR/.cache/huggingface" \
         "$ROOT_DIR/storage/uploads"

export HF_CACHE_DIR="${HF_CACHE_DIR:-$ROOT_DIR/.cache/huggingface}"
export HF_HOME="$HF_CACHE_DIR"
export TRANSFORMERS_CACHE="$HF_CACHE_DIR"
export HF_DATASETS_CACHE="${HF_DATASETS_CACHE:-$HF_CACHE_DIR/datasets}"
mkdir -p "$HF_DATASETS_CACHE"

# Persist environment hints for interactive shells
cat > "$ROOT_DIR/.env" <<EOF
# Auto-generated by setup.sh
HF_HOME=$HF_HOME
HF_CACHE_DIR=$HF_CACHE_DIR
TRANSFORMERS_CACHE=$TRANSFORMERS_CACHE
HF_DATASETS_CACHE=$HF_DATASETS_CACHE
PYTHONPATH=$ROOT_DIR
ENLENS_MODELS_DIR=$ROOT_DIR/models
ENLENS_DATA_DIR=$ROOT_DIR/data
EOF

# --------------- Python dependencies ---------------
python -m pip install --upgrade pip
python -m pip install -r "$ROOT_DIR/requirements.txt"

# --------------- NLP resources ---------------
python -m pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1.tar.gz
python -m nltk.downloader punkt stopwords averaged_perceptron_tagger

# --------------- Clone additional repositories ---------------
echo "ðŸ“¦ Cloning external repositories ..."

# BERT-KPE
if [[ ! -d "$ROOT_DIR/BERT-KPE/.git" ]]; then
  echo "ðŸ”¹ Cloning BERT-KPE repository ..."
  git clone https://github.com/thunlp/BERT-KPE.git "$ROOT_DIR/BERT-KPE" || echo "âš ï¸ BERT-KPE clone failed; continuing."
else
  echo "âœ… BERT-KPE already cloned."
fi

# TorqueClusteringPy
if [[ ! -d "$ROOT_DIR/TorqueClusteringPy/.git" ]]; then
  echo "ðŸ”¹ Cloning TorqueClusteringPy repository ..."
  git clone https://github.com/Cognet-74/TorqueClusteringPy.git "$ROOT_DIR/TorqueClusteringPy" || echo "âš ï¸ TorqueClusteringPy clone failed; continuing."
else
  echo "âœ… TorqueClusteringPy already cloned."
fi

# --------------- Legacy artifacts ---------------
set +e
python "$ROOT_DIR/download_legacy_models.py" --base-dir "$ROOT_DIR" \
  || echo "âš ï¸ Skipping legacy model download (non-fatal). Check link/permissions."

python "$ROOT_DIR/cache_hf_models.py" --cache-dir "$HF_CACHE_DIR" \
  || echo "âš ï¸ Skipping HF cache priming (non-fatal)."
set -e

# --------------- SDG globals injection ---------------
echo "ðŸ§­ Loading SDG target metadata from app_data/sdg_targets.json ..."
python - <<'PY'
import os, json, pathlib

root = pathlib.Path(os.getcwd())
app_data = root / "app_data"
env_dir = root / ".env"
env_dir.mkdir(exist_ok=True)

json_path = app_data / "sdg_targets.json"
globals_path = env_dir / ".globals"

if not json_path.exists():
    print(f"âš ï¸ Missing file: {json_path}. Skipping SDG globals creation.")
else:
    with open(json_path, "r") as f:
        sdg_targets = json.load(f)

    SDG_TARGETS = [
        "No Poverty", "Zero Hunger", "Good Health and Well-being", "Quality Education",
        "Gender Equality", "Clean Water and Sanitation", "Affordable and Clean Energy",
        "Decent Work and Economic Growth", "Industry, Innovation and Infrastructure",
        "Reduced Inequality", "Sustainable Cities and Communities",
        "Responsible Consumption and Production", "Climate Action", "Life Below Water",
        "Life on Land", "Peace, Justice and Strong Institutions"
    ]
    SDG_INDICATOR_CODES = list(sdg_targets.keys())
    SDG_INDICATORS = [f"{code}: {sdg_targets[code]}" for code in SDG_INDICATOR_CODES]

    with open(globals_path, "w", encoding="utf-8") as gf:
        gf.write("# Auto-generated globals for ENLENS runtime\n")
        gf.write("SDG_TARGETS = " + json.dumps(SDG_TARGETS, ensure_ascii=False, indent=2) + "\n")
        gf.write("SDG_INDICATOR_CODES = " + json.dumps(SDG_INDICATOR_CODES, ensure_ascii=False, indent=2) + "\n")
        gf.write("SDG_INDICATORS = " + json.dumps(SDG_INDICATORS, ensure_ascii=False, indent=2) + "\n")

    print(f"âœ… SDG globals written to {globals_path}")
PY

cat <<'MSG'

Setup complete. Activate the environment variables with:

  export $(grep -v '^#' .env | xargs)

Repositories cloned:
  - BERT-KPE
  - TorqueClusteringPy

The Hugging Face cache has been primed; subsequent runs will reuse local files.
MSG
